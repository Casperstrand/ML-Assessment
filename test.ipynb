{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmetizer = nltk.WordNetLemmatizer()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = [w for w in text if w.lower() not in stopwords]\n",
    "    return text\n",
    "\n",
    "def lemmetize_words(word_list):\n",
    "    lemmetized = [lemmetizer.lemmatize(w) for w in word_list]\n",
    "    return lemmetized\n",
    "\n",
    "def fix_text(row):\n",
    "    return ','.join(row)\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df = df.dropna()\n",
    "df['text'] = df['text'].apply(nltk.word_tokenize)\n",
    "df['text'] = df['text'].apply(remove_stop_words)\n",
    "df['text'] = df['text'].apply(lemmetize_words)\n",
    "df['text'] = df['text'].apply(fix_text)\n",
    "\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(df['text'], df['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(df['text'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(train_x)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC()\n",
    "SVM.fit(Train_X_Tfidf,train_y)\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, test_y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors' : [1,10]}\n",
    "grid = GridSearchCV(knn, parameters)\n",
    "grid.fit(Train_X_Tfidf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(Train_X_Tfidf, train_y)\n",
    "knn_predict = knn.predict(Test_X_Tfidf)\n",
    "print(accuracy_score(knn_predict, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8930fd93c0d0e39a0d4d9dd43e222c1e36af1b68c0e251fae90799f6ab1738d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
